{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2627eac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Chem' from 'rdkit' (/home/zhengyjo/chemprop-master/chemprop/rdkit.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8838/1427722564.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mchemprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchemprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_cache_mol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mempty_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchemprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_available_features_generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chemprop/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mchemprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchemprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchemprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchemprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchemprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muncertainty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chemprop/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcache_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_mol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMoleculeDatapoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMoleculeDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMoleculeDataLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mMoleculeSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_cache_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mempty_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_cache_mol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscaffold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_scaffold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_scaffold_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaffold_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaffold_to_smiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAtomBondScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilter_invalid_smiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_class_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_from_smiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chemprop/data/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAtomBondScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chemprop-master/chemprop/rdkit.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_mol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_h\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_h\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_atom_map\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Chem' from 'rdkit' (/home/zhengyjo/chemprop-master/chemprop/rdkit.py)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "import pickle\n",
    "from typing import List, Optional\n",
    "from typing_extensions import Literal\n",
    "from packaging import version\n",
    "from warnings import warn\n",
    "\n",
    "import torch\n",
    "from tap import Tap  # pip install typed-argument-parser (https://github.com/swansonk14/typed-argument-parser)\n",
    "import numpy as np\n",
    "\n",
    "import chemprop.data.utils\n",
    "from chemprop.data import set_cache_mol, empty_cache\n",
    "from chemprop.features import get_available_features_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5029741",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Chem' from 'rdkit' (/home/zhengyjo/chemprop-master/chemprop/rdkit.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8838/3754065443.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/chemprop-master/chemprop/rdkit.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_mol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_h\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_h\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_atom_map\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Chem' from 'rdkit' (/home/zhengyjo/chemprop-master/chemprop/rdkit.py)"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonArgs(Tap):\n",
    "    \"\"\":class:`CommonArgs` contains arguments that are used in both :class:`TrainArgs` and :class:`PredictArgs`.\"\"\"\n",
    "    smiles_columns: List[str] = None\n",
    "    \"\"\"List of names of the columns containing SMILES strings.\n",
    "    By default, uses the first :code:`number_of_molecules` columns.\"\"\"\n",
    "    number_of_molecules: int = 1\n",
    "    \"\"\"Number of molecules in each input to the model.\n",
    "    This must equal the length of :code:`smiles_columns` (if not :code:`None`).\"\"\"\n",
    "    checkpoint_dir: str = None\n",
    "    \"\"\"Directory from which to load model checkpoints (walks directory and ensembles all models that are found).\"\"\"\n",
    "    checkpoint_path: str = None\n",
    "    \"\"\"Path to model checkpoint (:code:`.pt` file).\"\"\"\n",
    "    checkpoint_paths: List[str] = None\n",
    "    \"\"\"List of paths to model checkpoints (:code:`.pt` files).\"\"\"\n",
    "    no_cuda: bool = False\n",
    "    \"\"\"Turn off cuda (i.e., use CPU instead of GPU).\"\"\"\n",
    "    gpu: int = None\n",
    "    \"\"\"Which GPU to use.\"\"\"\n",
    "    features_generator: List[str] = None\n",
    "    \"\"\"Method(s) of generating additional features.\"\"\"\n",
    "    features_path: List[str] = None\n",
    "    \"\"\"Path(s) to features to use in FNN (instead of features_generator).\"\"\"\n",
    "    phase_features_path: str = None\n",
    "    \"\"\"Path to features used to indicate the phase of the data in one-hot vector form. Used in spectra datatype.\"\"\"\n",
    "    no_features_scaling: bool = False\n",
    "    \"\"\"Turn off scaling of features.\"\"\"\n",
    "    max_data_size: int = None\n",
    "    \"\"\"Maximum number of data points to load.\"\"\"\n",
    "    num_workers: int = 8\n",
    "    \"\"\"Number of workers for the parallel data loading (0 means sequential).\"\"\"\n",
    "    batch_size: int = 50\n",
    "    \"\"\"Batch size.\"\"\"\n",
    "    atom_descriptors: Literal['feature', 'descriptor'] = None\n",
    "    \"\"\"\n",
    "    Custom extra atom descriptors.\n",
    "    :code:`feature`: used as atom features to featurize a given molecule.\n",
    "    :code:`descriptor`: used as descriptor and concatenated to the machine learned atomic representation.\n",
    "    \"\"\"\n",
    "    atom_descriptors_path: str = None\n",
    "    \"\"\"Path to the extra atom descriptors.\"\"\"\n",
    "    bond_descriptors: Literal['feature', 'descriptor'] = None\n",
    "    \"\"\"\n",
    "    Custom extra bond descriptors.\n",
    "    :code:`feature`: used as bond features to featurize a given molecule.\n",
    "    :code:`descriptor`: used as descriptor and concatenated to the machine learned bond representation.\n",
    "    \"\"\"\n",
    "    bond_descriptors_path: str = None\n",
    "    \"\"\"Path to the extra bond descriptors that will be used as bond features to featurize a given molecule.\"\"\"\n",
    "    no_cache_mol: bool = False\n",
    "    \"\"\"\n",
    "    Whether to not cache the RDKit molecule for each SMILES string to reduce memory usage (cached by default).\n",
    "    \"\"\"\n",
    "    empty_cache: bool = False\n",
    "    \"\"\"\n",
    "    Whether to empty all caches before training or predicting. This is necessary if multiple jobs are run within a single script and the atom or bond features change.\n",
    "    \"\"\"\n",
    "    constraints_path: str = None\n",
    "    \"\"\"\n",
    "    Path to constraints applied to atomic/bond properties prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CommonArgs, self).__init__(*args, **kwargs)\n",
    "        self._atom_features_size = 0\n",
    "        self._bond_features_size = 0\n",
    "        self._atom_descriptors_size = 0\n",
    "        self._bond_descriptors_size = 0\n",
    "        self._atom_constraints = []\n",
    "        self._bond_constraints = []\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        \"\"\"The :code:`torch.device` on which to load and process data and models.\"\"\"\n",
    "        if not self.cuda:\n",
    "            return torch.device('cpu')\n",
    "\n",
    "        return torch.device('cuda', self.gpu)\n",
    "\n",
    "    @device.setter\n",
    "    def device(self, device: torch.device) -> None:\n",
    "        self.cuda = device.type == 'cuda'\n",
    "        self.gpu = device.index\n",
    "\n",
    "    @property\n",
    "    def cuda(self) -> bool:\n",
    "        \"\"\"Whether to use CUDA (i.e., GPUs) or not.\"\"\"\n",
    "        return not self.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    @cuda.setter\n",
    "    def cuda(self, cuda: bool) -> None:\n",
    "        self.no_cuda = not cuda\n",
    "\n",
    "    @property\n",
    "    def features_scaling(self) -> bool:\n",
    "        \"\"\"\n",
    "        Whether to apply normalization with a :class:`~chemprop.data.scaler.StandardScaler`\n",
    "        to the additional molecule-level features.\n",
    "        \"\"\"\n",
    "        return not self.no_features_scaling\n",
    "\n",
    "    @features_scaling.setter\n",
    "    def features_scaling(self, features_scaling: bool) -> None:\n",
    "        self.no_features_scaling = not features_scaling\n",
    "\n",
    "    @property\n",
    "    def atom_features_size(self) -> int:\n",
    "        \"\"\"The size of the atom features.\"\"\"\n",
    "        return self._atom_features_size\n",
    "\n",
    "    @atom_features_size.setter\n",
    "    def atom_features_size(self, atom_features_size: int) -> None:\n",
    "        self._atom_features_size = atom_features_size\n",
    "\n",
    "    @property\n",
    "    def atom_descriptors_size(self) -> int:\n",
    "        \"\"\"The size of the atom descriptors.\"\"\"\n",
    "        return self._atom_descriptors_size\n",
    "\n",
    "    @atom_descriptors_size.setter\n",
    "    def atom_descriptors_size(self, atom_descriptors_size: int) -> None:\n",
    "        self._atom_descriptors_size = atom_descriptors_size\n",
    "\n",
    "    @property\n",
    "    def bond_features_size(self) -> int:\n",
    "        \"\"\"The size of the atom features.\"\"\"\n",
    "        return self._bond_features_size\n",
    "\n",
    "    @bond_features_size.setter\n",
    "    def bond_features_size(self, bond_features_size: int) -> None:\n",
    "        self._bond_features_size = bond_features_size\n",
    "\n",
    "    @property\n",
    "    def bond_descriptors_size(self) -> int:\n",
    "        \"\"\"The size of the bond descriptors.\"\"\"\n",
    "        return self._bond_descriptors_size\n",
    "\n",
    "    @bond_descriptors_size.setter\n",
    "    def bond_descriptors_size(self, bond_descriptors_size: int) -> None:\n",
    "        self._bond_descriptors_size = bond_descriptors_size\n",
    "\n",
    "    def configure(self) -> None:\n",
    "        self.add_argument('--gpu', choices=list(range(torch.cuda.device_count())))\n",
    "        self.add_argument('--features_generator', choices=get_available_features_generators())\n",
    "\n",
    "    def process_args(self) -> None:\n",
    "        # Load checkpoint paths\n",
    "        self.checkpoint_paths = get_checkpoint_paths(\n",
    "            checkpoint_path=self.checkpoint_path,\n",
    "            checkpoint_paths=self.checkpoint_paths,\n",
    "            checkpoint_dir=self.checkpoint_dir,\n",
    "        )\n",
    "\n",
    "        # Validate features\n",
    "        if self.features_generator is not None and 'rdkit_2d_normalized' in self.features_generator and self.features_scaling:\n",
    "            raise ValueError('When using rdkit_2d_normalized features, --no_features_scaling must be specified.')\n",
    "\n",
    "        # Validate atom descriptors\n",
    "        if (self.atom_descriptors is None) != (self.atom_descriptors_path is None):\n",
    "            raise ValueError('If atom_descriptors is specified, then an atom_descriptors_path must be provided '\n",
    "                             'and vice versa.')\n",
    "\n",
    "        if self.atom_descriptors is not None and self.number_of_molecules > 1:\n",
    "            raise NotImplementedError('Atom descriptors are currently only supported with one molecule '\n",
    "                                      'per input (i.e., number_of_molecules = 1).')\n",
    "\n",
    "        # Validate bond descriptors\n",
    "        if (self.bond_descriptors is None) != (self.bond_descriptors_path is None):\n",
    "            raise ValueError('If bond_descriptors is specified, then an bond_descriptors_path must be provided '\n",
    "                             'and vice versa.')\n",
    "\n",
    "        if self.bond_descriptors is not None and self.number_of_molecules > 1:\n",
    "            raise NotImplementedError('Bond descriptors are currently only supported with one molecule '\n",
    "                                      'per input (i.e., number_of_molecules = 1).')\n",
    "\n",
    "        set_cache_mol(not self.no_cache_mol)\n",
    "\n",
    "        if self.empty_cache:\n",
    "            empty_cache()\n",
    "\n",
    "\n",
    "class TrainArgs(CommonArgs):\n",
    "    \"\"\":class:`TrainArgs` includes :class:`CommonArgs` along with additional arguments used for training a Chemprop model.\"\"\"\n",
    "\n",
    "    # General arguments\n",
    "    data_path: str\n",
    "    \"\"\"Path to data CSV file.\"\"\"\n",
    "    encoder_path: str\n",
    "    \"\"\"Path to pretrained encoder model weight.\"\"\"\n",
    "    target_columns: List[str] = None\n",
    "    \"\"\"\n",
    "    Name of the columns containing target values.\n",
    "    By default, uses all columns except the SMILES column and the :code:`ignore_columns`.\n",
    "    \"\"\"\n",
    "    ignore_columns: List[str] = None\n",
    "    \"\"\"Name of the columns to ignore when :code:`target_columns` is not provided.\"\"\"\n",
    "    dataset_type: Literal['regression', 'classification', 'multiclass', 'spectra','kmgcl'] # I add kmgcl to the dataset type\n",
    "    \"\"\"Type of dataset. This determines the default loss function used during training.\"\"\"\n",
    "    loss_function: Literal['mse', 'bounded_mse', 'binary_cross_entropy', 'cross_entropy', 'mcc', 'sid', 'wasserstein', 'mve', 'evidential', 'dirichlet','kmgcl'] = None # I add kmgcl to the dataset type\n",
    "    \"\"\"Choice of loss function. Loss functions are limited to compatible dataset types.\"\"\"\n",
    "    multiclass_num_classes: int = 3\n",
    "    \"\"\"Number of classes when running multiclass classification.\"\"\"\n",
    "    separate_val_path: str = None\n",
    "    \"\"\"Path to separate val set, optional.\"\"\"\n",
    "    separate_test_path: str = None\n",
    "    \"\"\"Path to separate test set, optional.\"\"\"\n",
    "    spectra_phase_mask_path: str = None\n",
    "    \"\"\"Path to a file containing a phase mask array, used for excluding particular regions in spectra predictions.\"\"\"\n",
    "    data_weights_path: str = None\n",
    "    \"\"\"Path to weights for each molecule in the training data, affecting the relative weight of molecules in the loss function\"\"\"\n",
    "    target_weights: List[float] = None\n",
    "    \"\"\"Weights associated with each target, affecting the relative weight of targets in the loss function. Must match the number of target columns.\"\"\"\n",
    "    split_type: Literal['random', 'scaffold_balanced', 'predetermined', 'crossval', 'cv', 'cv-no-test', 'index_predetermined', 'random_with_repeated_smiles', 'molecular_weight'] = 'random'\n",
    "    \"\"\"Method of splitting the data into train/val/test.\"\"\"\n",
    "    split_sizes: List[float] = None\n",
    "    \"\"\"Split proportions for train/validation/test sets.\"\"\"\n",
    "    split_key_molecule: int = 0\n",
    "    \"\"\"The index of the key molecule used for splitting when multiple molecules are present and constrained split_type is used, like scaffold_balanced or random_with_repeated_smiles.\n",
    "       Note that this index begins with zero for the first molecule.\"\"\"\n",
    "    num_folds: int = 1\n",
    "    \"\"\"Number of folds when performing cross validation.\"\"\"\n",
    "    folds_file: str = None\n",
    "    \"\"\"Optional file of fold labels.\"\"\"\n",
    "    val_fold_index: int = None\n",
    "    \"\"\"Which fold to use as val for leave-one-out cross val.\"\"\"\n",
    "    test_fold_index: int = None\n",
    "    \"\"\"Which fold to use as test for leave-one-out cross val.\"\"\"\n",
    "    crossval_index_dir: str = None\n",
    "    \"\"\"Directory in which to find cross validation index files.\"\"\"\n",
    "    crossval_index_file: str = None\n",
    "    \"\"\"Indices of files to use as train/val/test. Overrides :code:`--num_folds` and :code:`--seed`.\"\"\"\n",
    "    seed: int = 0\n",
    "    \"\"\"\n",
    "    Random seed to use when splitting data into train/val/test sets.\n",
    "    When :code`num_folds > 1`, the first fold uses this seed and all subsequent folds add 1 to the seed.\n",
    "    \"\"\"\n",
    "    pytorch_seed: int = 0\n",
    "    \"\"\"Seed for PyTorch randomness (e.g., random initial weights).\"\"\"\n",
    "    metric: Metric = None\n",
    "    \"\"\"\n",
    "    Metric to use during evaluation. It is also used with the validation set for early stopping.\n",
    "    Defaults to \"auc\" for classification, \"rmse\" for regression, and \"sid\" for spectra.\n",
    "    \"\"\"\n",
    "    extra_metrics: List[Metric] = []\n",
    "    \"\"\"Additional metrics to use to evaluate the model. Not used for early stopping.\"\"\"\n",
    "    save_dir: str = None\n",
    "    \"\"\"Directory where model checkpoints will be saved.\"\"\"\n",
    "    checkpoint_frzn: str = None\n",
    "    \"\"\"Path to model checkpoint file to be loaded for overwriting and freezing weights.\"\"\"\n",
    "    save_smiles_splits: bool = False\n",
    "    \"\"\"Save smiles for each train/val/test splits for prediction convenience later.\"\"\"\n",
    "    test: bool = False\n",
    "    \"\"\"Whether to skip training and only test the model.\"\"\"\n",
    "    quiet: bool = False\n",
    "    \"\"\"Skip non-essential print statements.\"\"\"\n",
    "    log_frequency: int = 10\n",
    "    \"\"\"The number of batches between each logging of the training loss.\"\"\"\n",
    "    show_individual_scores: bool = False\n",
    "    \"\"\"Show all scores for individual targets, not just average, at the end.\"\"\"\n",
    "    cache_cutoff: float = 10000\n",
    "    \"\"\"\n",
    "    Maximum number of molecules in dataset to allow caching.\n",
    "    Below this number, caching is used and data loading is sequential.\n",
    "    Above this number, caching is not used and data loading is parallel.\n",
    "    Use \"inf\" to always cache.\n",
    "    \"\"\"\n",
    "    save_preds: bool = False\n",
    "    \"\"\"Whether to save test split predictions during training.\"\"\"\n",
    "    resume_experiment: bool = False\n",
    "    \"\"\"\n",
    "    Whether to resume the experiment.\n",
    "    Loads test results from any folds that have already been completed and skips training those folds.\n",
    "    \"\"\"\n",
    "\n",
    "    # Model arguments\n",
    "    bias: bool = False\n",
    "    \"\"\"Whether to add bias to linear layers.\"\"\"\n",
    "    hidden_size: int = 300\n",
    "    \"\"\"Dimensionality of hidden layers in MPN.\"\"\"\n",
    "    depth: int = 3\n",
    "    \"\"\"Number of message passing steps.\"\"\"\n",
    "    bias_solvent: bool = False\n",
    "    \"\"\"Whether to add bias to linear layers for solvent MPN if :code:`reaction_solvent` is True.\"\"\"\n",
    "    hidden_size_solvent: int = 300\n",
    "    \"\"\"Dimensionality of hidden layers in solvent MPN if :code:`reaction_solvent` is True.\"\"\"\n",
    "    depth_solvent: int = 3\n",
    "    \"\"\"Number of message passing steps for solvent if :code:`reaction_solvent` is True.\"\"\"\n",
    "    mpn_shared: bool = False\n",
    "    \"\"\"Whether to use the same message passing neural network for all input molecules\n",
    "    Only relevant if :code:`number_of_molecules > 1`\"\"\"\n",
    "    dropout: float = 0.0\n",
    "    \"\"\"Dropout probability.\"\"\"\n",
    "    activation: Literal['ReLU', 'LeakyReLU', 'PReLU', 'tanh', 'SELU', 'ELU'] = 'ReLU'\n",
    "    \"\"\"Activation function.\"\"\"\n",
    "    atom_messages: bool = False\n",
    "    \"\"\"Centers messages on atoms instead of on bonds.\"\"\"\n",
    "    undirected: bool = False\n",
    "    \"\"\"Undirected edges (always sum the two relevant bond vectors).\"\"\"\n",
    "    ffn_hidden_size: int = None\n",
    "    \"\"\"Hidden dim for higher-capacity FFN (defaults to hidden_size).\"\"\"\n",
    "    ffn_num_layers: int = 2\n",
    "    \"\"\"Number of layers in FFN after MPN encoding.\"\"\"\n",
    "    features_only: bool = False\n",
    "    \"\"\"Use only the additional features in an FFN, no graph network.\"\"\"\n",
    "    separate_val_features_path: List[str] = None\n",
    "    \"\"\"Path to file with features for separate val set.\"\"\"\n",
    "    separate_test_features_path: List[str] = None\n",
    "    \"\"\"Path to file with features for separate test set.\"\"\"\n",
    "    separate_val_phase_features_path: str = None\n",
    "    \"\"\"Path to file with phase features for separate val set.\"\"\"\n",
    "    separate_test_phase_features_path: str = None\n",
    "    \"\"\"Path to file with phase features for separate test set.\"\"\"\n",
    "    separate_val_atom_descriptors_path: str = None\n",
    "    \"\"\"Path to file with extra atom descriptors for separate val set.\"\"\"\n",
    "    separate_test_atom_descriptors_path: str = None\n",
    "    \"\"\"Path to file with extra atom descriptors for separate test set.\"\"\"\n",
    "    separate_val_bond_descriptors_path: str = None\n",
    "    \"\"\"Path to file with extra atom descriptors for separate val set.\"\"\"\n",
    "    separate_test_bond_descriptors_path: str = None\n",
    "    \"\"\"Path to file with extra atom descriptors for separate test set.\"\"\"\n",
    "    separate_val_constraints_path: str = None\n",
    "    \"\"\"Path to file with constraints for separate val set.\"\"\"\n",
    "    separate_test_constraints_path: str = None\n",
    "    \"\"\"Path to file with constraints for separate test set.\"\"\"\n",
    "    config_path: str = None\n",
    "    \"\"\"\n",
    "    Path to a :code:`.json` file containing arguments. Any arguments present in the config file\n",
    "    will override arguments specified via the command line or by the defaults.\n",
    "    \"\"\"\n",
    "    ensemble_size: int = 1\n",
    "    \"\"\"Number of models in ensemble.\"\"\"\n",
    "    aggregation: Literal['mean', 'sum', 'norm'] = 'mean'\n",
    "    \"\"\"Aggregation scheme for atomic vectors into molecular vectors\"\"\"\n",
    "    aggregation_norm: int = 100\n",
    "    \"\"\"For norm aggregation, number by which to divide summed up atomic features\"\"\"\n",
    "    reaction: bool = False\n",
    "    \"\"\"\n",
    "    Whether to adjust MPNN layer to take reactions as input instead of molecules.\n",
    "    \"\"\"\n",
    "    reaction_mode: Literal['reac_prod', 'reac_diff', 'prod_diff', 'reac_prod_balance', 'reac_diff_balance', 'prod_diff_balance'] = 'reac_diff'\n",
    "    \"\"\"\n",
    "    Choices for construction of atom and bond features for reactions\n",
    "    :code:`reac_prod`: concatenates the reactants feature with the products feature.\n",
    "    :code:`reac_diff`: concatenates the reactants feature with the difference in features between reactants and products.\n",
    "    :code:`prod_diff`: concatenates the products feature with the difference in features between reactants and products.\n",
    "    :code:`reac_prod_balance`: concatenates the reactants feature with the products feature, balances imbalanced reactions.\n",
    "    :code:`reac_diff_balance`: concatenates the reactants feature with the difference in features between reactants and products, balances imbalanced reactions.\n",
    "    :code:`prod_diff_balance`: concatenates the products feature with the difference in features between reactants and products, balances imbalanced reactions.\n",
    "    \"\"\"\n",
    "    reaction_solvent: bool = False\n",
    "    \"\"\"\n",
    "    Whether to adjust the MPNN layer to take as input a reaction and a molecule, and to encode them with separate MPNNs.\n",
    "    \"\"\"\n",
    "    explicit_h: bool = False\n",
    "    \"\"\"\n",
    "    Whether H are explicitly specified in input (and should be kept this way). This option is intended to be used\n",
    "    with the :code:`reaction` or :code:`reaction_solvent` options, and applies only to the reaction part.\n",
    "    \"\"\"\n",
    "    adding_h: bool = False\n",
    "    \"\"\"\n",
    "    Whether RDKit molecules will be constructed with adding the Hs to them. This option is intended to be used\n",
    "    with Chemprop's default molecule or multi-molecule encoders, or in :code:`reaction_solvent` mode where it applies to the solvent only.\n",
    "    \"\"\"\n",
    "    is_atom_bond_targets: bool = False\n",
    "    \"\"\"\n",
    "    whether this is atomic/bond properties prediction.\n",
    "    \"\"\"\n",
    "    keeping_atom_map: bool = False\n",
    "    \"\"\"\n",
    "    Whether RDKit molecules keep the original atom mapping. This option is intended to be used when providing atom-mapped SMILES with\n",
    "    the :code:`is_atom_bond_targets`.\n",
    "    \"\"\"\n",
    "    no_shared_atom_bond_ffn: bool = False\n",
    "    \"\"\"\n",
    "    Whether the FFN weights for atom and bond targets should be independent between tasks.\n",
    "    \"\"\"\n",
    "    weights_ffn_num_layers: int = 2\n",
    "    \"\"\"\n",
    "    Number of layers in FFN for determining weights used in constrained targets.\n",
    "    \"\"\"\n",
    "    no_adding_bond_types: bool = False\n",
    "    \"\"\"\n",
    "    Whether the bond types determined by RDKit molecules added to the output of bond targets. This option is intended to be used\n",
    "    with the :code:`is_atom_bond_targets`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Training arguments\n",
    "    epochs: int = 30\n",
    "    \"\"\"Number of epochs to run.\"\"\"\n",
    "    warmup_epochs: float = 2.0\n",
    "    \"\"\"\n",
    "    Number of epochs during which learning rate increases linearly from :code:`init_lr` to :code:`max_lr`.\n",
    "    Afterwards, learning rate decreases exponentially from :code:`max_lr` to :code:`final_lr`.\n",
    "    \"\"\"\n",
    "    init_lr: float = 1e-4\n",
    "    \"\"\"Initial learning rate.\"\"\"\n",
    "    max_lr: float = 1e-3\n",
    "    \"\"\"Maximum learning rate.\"\"\"\n",
    "    final_lr: float = 1e-4\n",
    "    \"\"\"Final learning rate.\"\"\"\n",
    "    grad_clip: float = None\n",
    "    \"\"\"Maximum magnitude of gradient during training.\"\"\"\n",
    "    class_balance: bool = False\n",
    "    \"\"\"Trains with an equal number of positives and negatives in each batch.\"\"\"\n",
    "    spectra_activation: Literal['exp', 'softplus'] = 'exp'\n",
    "    \"\"\"Indicates which function to use in dataset_type spectra training to constrain outputs to be positive.\"\"\"\n",
    "    spectra_target_floor: float = 1e-8\n",
    "    \"\"\"Values in targets for dataset type spectra are replaced with this value, intended to be a small positive number used to enforce positive values.\"\"\"\n",
    "    evidential_regularization: float = 0\n",
    "    \"\"\"Value used in regularization for evidential loss function. The default value recommended by Soleimany et al.(2021) is 0.2. \n",
    "    Optimal value is dataset-dependent; it is recommended that users test different values to find the best value for their model.\"\"\"\n",
    "    overwrite_default_atom_features: bool = False\n",
    "    \"\"\"\n",
    "    Overwrites the default atom descriptors with the new ones instead of concatenating them.\n",
    "    Can only be used if atom_descriptors are used as a feature.\n",
    "    \"\"\"\n",
    "    no_atom_descriptor_scaling: bool = False\n",
    "    \"\"\"Turn off atom feature scaling.\"\"\"\n",
    "    overwrite_default_bond_features: bool = False\n",
    "    \"\"\"\n",
    "    Overwrites the default bond descriptors with the new ones instead of concatenating them.\n",
    "    Can only be used if bond_descriptors are used as a feature.\n",
    "    \"\"\"\n",
    "    no_bond_descriptor_scaling: bool = False\n",
    "    \"\"\"Turn off atom feature scaling.\"\"\"\n",
    "    frzn_ffn_layers: int = 0\n",
    "    \"\"\"\n",
    "    Overwrites weights for the first n layers of the ffn from checkpoint model (specified checkpoint_frzn),\n",
    "    where n is specified in the input.\n",
    "    Automatically also freezes mpnn weights.\n",
    "    \"\"\"\n",
    "    freeze_first_only: bool = False\n",
    "    \"\"\"\n",
    "    Determines whether or not to use checkpoint_frzn for just the first encoder.\n",
    "    Default (False) is to use the checkpoint to freeze all encoders.\n",
    "    (only relevant for number_of_molecules > 1, where checkpoint model has number_of_molecules = 1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super(TrainArgs, self).__init__(*args, **kwargs)\n",
    "        self._task_names = None\n",
    "        self._crossval_index_sets = None\n",
    "        self._task_names = None\n",
    "        self._num_tasks = None\n",
    "        self._features_size = None\n",
    "        self._train_data_size = None\n",
    "    \n",
    "#     @property\n",
    "#     def encoder_path(self) -> str:\n",
    "#         \"\"\"Pretrained encoder pt file path being trained on.\"\"\"\n",
    "#         return self.encoder_path\n",
    "    \n",
    "#     @encoder_path.setter\n",
    "#     def encoder_path(self, encoder_path: str) -> None:\n",
    "#         self.encoder_path = encoder_path\n",
    "\n",
    "    @property\n",
    "    def metrics(self) -> List[str]:\n",
    "        \"\"\"The list of metrics used for evaluation. Only the first is used for early stopping.\"\"\"\n",
    "        return [self.metric] + self.extra_metrics\n",
    "\n",
    "    @property\n",
    "    def minimize_score(self) -> bool:\n",
    "        \"\"\"Whether the model should try to minimize the score metric or maximize it.\"\"\"\n",
    "        return self.metric in {'rmse', 'mae', 'mse', 'cross_entropy', 'binary_cross_entropy', 'sid', 'wasserstein', 'bounded_mse', 'bounded_mae', 'bounded_rmse'}\n",
    "\n",
    "    @property\n",
    "    def use_input_features(self) -> bool:\n",
    "        \"\"\"Whether the model is using additional molecule-level features.\"\"\"\n",
    "        return self.features_generator is not None or self.features_path is not None or self.phase_features_path is not None\n",
    "\n",
    "    @property\n",
    "    def num_lrs(self) -> int:\n",
    "        \"\"\"The number of learning rates to use (currently hard-coded to 1).\"\"\"\n",
    "        return 1\n",
    "\n",
    "    @property\n",
    "    def crossval_index_sets(self) -> List[List[List[int]]]:\n",
    "        \"\"\"Index sets used for splitting data into train/validation/test during cross-validation\"\"\"\n",
    "        return self._crossval_index_sets\n",
    "\n",
    "    @property\n",
    "    def task_names(self) -> List[str]:\n",
    "        \"\"\"A list of names of the tasks being trained on.\"\"\"\n",
    "        return self._task_names\n",
    "\n",
    "    @task_names.setter\n",
    "    def task_names(self, task_names: List[str]) -> None:\n",
    "        self._task_names = task_names\n",
    "\n",
    "    @property\n",
    "    def num_tasks(self) -> int:\n",
    "        \"\"\"The number of tasks being trained on.\"\"\"\n",
    "        return len(self.task_names) if self.task_names is not None else 0\n",
    "\n",
    "    @property\n",
    "    def features_size(self) -> int:\n",
    "        \"\"\"The dimensionality of the additional molecule-level features.\"\"\"\n",
    "        return self._features_size\n",
    "\n",
    "    @features_size.setter\n",
    "    def features_size(self, features_size: int) -> None:\n",
    "        self._features_size = features_size\n",
    "\n",
    "    @property\n",
    "    def train_data_size(self) -> int:\n",
    "        \"\"\"The size of the training data set.\"\"\"\n",
    "        return self._train_data_size\n",
    "\n",
    "    @train_data_size.setter\n",
    "    def train_data_size(self, train_data_size: int) -> None:\n",
    "        self._train_data_size = train_data_size\n",
    "\n",
    "    @property\n",
    "    def atom_descriptor_scaling(self) -> bool:\n",
    "        \"\"\"\n",
    "        Whether to apply normalization with a :class:`~chemprop.data.scaler.StandardScaler`\n",
    "        to the additional atom features.\"\n",
    "        \"\"\"\n",
    "        return not self.no_atom_descriptor_scaling\n",
    "\n",
    "    @property\n",
    "    def bond_descriptor_scaling(self) -> bool:\n",
    "        \"\"\"\n",
    "        Whether to apply normalization with a :class:`~chemprop.data.scaler.StandardScaler`\n",
    "        to the additional bond features.\"\n",
    "        \"\"\"\n",
    "        return not self.no_bond_descriptor_scaling\n",
    "    \n",
    "    @property\n",
    "    def shared_atom_bond_ffn(self) -> bool:\n",
    "        \"\"\"\n",
    "        Whether the FFN weights for atom and bond targets should be shared between tasks.\n",
    "        \"\"\"\n",
    "        return not self.no_shared_atom_bond_ffn\n",
    "\n",
    "    @property\n",
    "    def adding_bond_types(self) -> bool:\n",
    "        \"\"\"\n",
    "        Whether the bond types determined by RDKit molecules should be added to the output of bond targets.\n",
    "        \"\"\"\n",
    "        return not self.no_adding_bond_types\n",
    "\n",
    "    @property\n",
    "    def atom_constraints(self) -> List[bool]:\n",
    "        \"\"\"\n",
    "        A list of booleans indicating whether constraints applied to output of atomic properties.\n",
    "        \"\"\"\n",
    "        if self.is_atom_bond_targets and self.constraints_path:\n",
    "            if not self._atom_constraints:\n",
    "                header = chemprop.data.utils.get_header(self.constraints_path)\n",
    "                self._atom_constraints = [target in header for target in self.atom_targets]\n",
    "        else:\n",
    "            self._atom_constraints = [False] * len(self.atom_targets)\n",
    "        return self._atom_constraints\n",
    "\n",
    "    @property\n",
    "    def bond_constraints(self) -> List[bool]:\n",
    "        \"\"\"\n",
    "        A list of booleans indicating whether constraints applied to output of bond properties.\n",
    "        \"\"\"\n",
    "        if self.is_atom_bond_targets and self.constraints_path:\n",
    "            if not self._bond_constraints:\n",
    "                header = chemprop.data.utils.get_header(self.constraints_path)\n",
    "                self._bond_constraints = [target in header for target in self.bond_targets]\n",
    "        else:\n",
    "            self._bond_constraints = [False] * len(self.bond_targets)\n",
    "        return self._bond_constraints\n",
    "\n",
    "    def process_args(self) -> None:\n",
    "        super(TrainArgs, self).process_args()\n",
    "\n",
    "        global temp_save_dir  # Prevents the temporary directory from being deleted upon function return\n",
    "\n",
    "        # Adapt the number of molecules for reaction_solvent mode\n",
    "        if self.reaction_solvent is True and self.number_of_molecules != 2:\n",
    "            raise ValueError('In reaction_solvent mode, --number_of_molecules 2 must be specified.')\n",
    "\n",
    "        # Process SMILES columns\n",
    "        self.smiles_columns = chemprop.data.utils.preprocess_smiles_columns(\n",
    "            path=self.data_path,\n",
    "            smiles_columns=self.smiles_columns,\n",
    "            number_of_molecules=self.number_of_molecules,\n",
    "        )\n",
    "\n",
    "        # Load config file\n",
    "        if self.config_path is not None:\n",
    "            with open(self.config_path) as f:\n",
    "                config = json.load(f)\n",
    "                for key, value in config.items():\n",
    "                    setattr(self, key, value)\n",
    "\n",
    "        # Determine the target_columns when training atomic and bond targets\n",
    "        if self.is_atom_bond_targets:\n",
    "            self.atom_targets, self.bond_targets, self.molecule_targets = chemprop.data.utils.get_mixed_task_names(\n",
    "                path=self.data_path,\n",
    "                smiles_columns=self.smiles_columns,\n",
    "                target_columns=self.target_columns,\n",
    "                ignore_columns=self.ignore_columns,\n",
    "                keep_h=self.explicit_h,\n",
    "                add_h=self.adding_h,\n",
    "                keep_atom_map=self.keeping_atom_map,\n",
    "            )\n",
    "            self.target_columns = self.atom_targets + self.bond_targets\n",
    "            # self.target_columns = self.atom_targets + self.bond_targets + self.molecule_targets  # TODO: Support mixed targets\n",
    "        else:\n",
    "            self.atom_targets, self.bond_targets = [], []\n",
    "\n",
    "        # Check whether atomic/bond constraints have been applied on the correct dataset_type\n",
    "        if self.constraints_path:\n",
    "            if not self.is_atom_bond_targets:\n",
    "                raise ValueError('Constraints on atomic/bond targets can only be used in atomic/bond properties prediction.')\n",
    "            if self.dataset_type != 'regression':\n",
    "                raise ValueError(f'In atomic/bond properties prediction, atomic/bond constraints are not supported for {self.dataset_type}.')\n",
    "\n",
    "        # Check whether the number of input columns is one for the atomic/bond mode\n",
    "        if self.is_atom_bond_targets:\n",
    "            if self.number_of_molecules != 1:\n",
    "                raise ValueError('In atomic/bond properties prediction, exactly one smiles column must be provided.')\n",
    "\n",
    "        # Check whether the number of input columns is two for the reaction_solvent mode\n",
    "        if self.reaction_solvent is True and len(self.smiles_columns) != 2:\n",
    "            raise ValueError('In reaction_solvent mode, exactly two smiles column must be provided (one for reactions, and one for molecules)')\n",
    "\n",
    "        # Validate reaction/reaction_solvent mode\n",
    "        if self.reaction is True and self.reaction_solvent is True:\n",
    "            raise ValueError('Only reaction or reaction_solvent mode can be used, not both.')\n",
    "\n",
    "        # Create temporary directory as save directory if not provided\n",
    "        if self.save_dir is None:\n",
    "            temp_save_dir = TemporaryDirectory()\n",
    "            self.save_dir = temp_save_dir.name\n",
    "\n",
    "        # Fix ensemble size if loading checkpoints\n",
    "        if self.checkpoint_paths is not None and len(self.checkpoint_paths) > 0:\n",
    "            self.ensemble_size = len(self.checkpoint_paths)\n",
    "\n",
    "        # Process and validate metric and loss function\n",
    "        if self.metric is None:\n",
    "            if self.dataset_type == 'classification':\n",
    "                self.metric = 'auc'\n",
    "            elif self.dataset_type == 'multiclass':\n",
    "                self.metric = 'cross_entropy'\n",
    "            elif self.dataset_type == 'kmgcl':\n",
    "                self.metric = 'kmgcl'\n",
    "            elif self.dataset_type == 'spectra':\n",
    "                self.metric = 'sid'\n",
    "            elif self.dataset_type == 'regression' and self.loss_function == 'bounded_mse':\n",
    "                self.metric = 'bounded_mse'\n",
    "            elif self.dataset_type == 'regression':\n",
    "                self.metric = 'rmse'\n",
    "            else:\n",
    "                raise ValueError(f'Dataset type {self.dataset_type} is not supported.')\n",
    "\n",
    "        if self.metric in self.extra_metrics:\n",
    "            raise ValueError(f'Metric {self.metric} is both the metric and is in extra_metrics. '\n",
    "                             f'Please only include it once.')\n",
    "\n",
    "        # Add kmgcl to the metric configuration\n",
    "        for metric in self.metrics:\n",
    "            if not any([(self.dataset_type == 'classification' and metric in ['auc', 'prc-auc', 'accuracy', 'binary_cross_entropy', 'f1', 'mcc']),\n",
    "                        (self.dataset_type == 'regression' and metric in ['rmse', 'mae', 'mse', 'r2', 'bounded_rmse', 'bounded_mae', 'bounded_mse']),\n",
    "                        (self.dataset_type == 'multiclass' and metric in ['cross_entropy', 'accuracy', 'f1', 'mcc']),\n",
    "                        (self.dataset_type == 'kmgcl' and metric in ['kmgcl']),\n",
    "                        (self.dataset_type == 'spectra' and metric in ['sid', 'wasserstein'])]):\n",
    "                raise ValueError(f'Metric \"{metric}\" invalid for dataset type \"{self.dataset_type}\".')\n",
    "\n",
    "        # Add kmgcl to the loss function\n",
    "        if self.loss_function is None:\n",
    "            if self.dataset_type == 'classification':\n",
    "                self.loss_function = 'binary_cross_entropy'\n",
    "            elif self.dataset_type == 'multiclass':\n",
    "                self.loss_function = 'cross_entropy'\n",
    "            elif self.dataset_type == 'spectra':\n",
    "                self.loss_function = 'sid'\n",
    "            elif self.dataset_type == 'regression':\n",
    "                self.loss_function = 'mse'\n",
    "            elif self.dataset_type == 'kmgcl':\n",
    "                self.loss_function = 'kmgcl'\n",
    "            else:\n",
    "                raise ValueError(f'Default loss function not configured for dataset type {self.dataset_type}.')\n",
    "\n",
    "        if self.loss_function != 'bounded_mse' and any(metric in ['bounded_mse', 'bounded_rmse', 'bounded_mae'] for metric in self.metrics):\n",
    "            raise ValueError('Bounded metrics can only be used in conjunction with the regression loss function bounded_mse.')\n",
    "\n",
    "        # Validate class balance\n",
    "        if self.class_balance and self.dataset_type != 'classification':\n",
    "            raise ValueError('Class balance can only be applied if the dataset type is classification.')\n",
    "\n",
    "        # Validate features\n",
    "        if self.features_only and not (self.features_generator or self.features_path):\n",
    "            raise ValueError('When using features_only, a features_generator or features_path must be provided.')\n",
    "\n",
    "        # Handle FFN hidden size\n",
    "        if self.ffn_hidden_size is None:\n",
    "            self.ffn_hidden_size = self.hidden_size\n",
    "\n",
    "        # Handle MPN variants\n",
    "        if self.atom_messages and self.undirected:\n",
    "            raise ValueError('Undirected is unnecessary when using atom_messages '\n",
    "                             'since atom_messages are by their nature undirected.')\n",
    "\n",
    "        # Validate split type settings\n",
    "        if not (self.split_type == 'predetermined') == (self.folds_file is not None) == (self.test_fold_index is not None):\n",
    "            raise ValueError('When using predetermined split type, must provide folds_file and test_fold_index.')\n",
    "\n",
    "        if not (self.split_type == 'crossval') == (self.crossval_index_dir is not None):\n",
    "            raise ValueError('When using crossval split type, must provide crossval_index_dir.')\n",
    "\n",
    "        if not (self.split_type in ['crossval', 'index_predetermined']) == (self.crossval_index_file is not None):\n",
    "            raise ValueError('When using crossval or index_predetermined split type, must provide crossval_index_file.')\n",
    "\n",
    "        if self.split_type in ['crossval', 'index_predetermined']:\n",
    "            with open(self.crossval_index_file, 'rb') as rf:\n",
    "                self._crossval_index_sets = pickle.load(rf)\n",
    "            self.num_folds = len(self.crossval_index_sets)\n",
    "            self.seed = 0\n",
    "\n",
    "        # Validate split size entry and set default values\n",
    "        if self.split_sizes is None:\n",
    "            if self.separate_val_path is None and self.separate_test_path is None: # separate data paths are not provided\n",
    "                self.split_sizes = [0.8, 0.1, 0.1]\n",
    "            elif self.separate_val_path is not None and self.separate_test_path is None: # separate val path only\n",
    "                self.split_sizes = [0.8, 0., 0.2]\n",
    "            elif self.separate_val_path is None and self.separate_test_path is not None: # separate test path only\n",
    "                self.split_sizes = [0.8, 0.2, 0.]\n",
    "            else: # both separate data paths are provided\n",
    "                self.split_sizes = [1., 0., 0.]\n",
    "\n",
    "        else:\n",
    "            if not np.isclose(sum(self.split_sizes), 1):\n",
    "                raise ValueError(f'Provided split sizes of {self.split_sizes} do not sum to 1.')\n",
    "            if any([size < 0 for size in self.split_sizes]):\n",
    "                raise ValueError(f'Split sizes must be non-negative. Received split sizes: {self.split_sizes}')\n",
    "\n",
    "\n",
    "            if len(self.split_sizes) not in [2, 3]:\n",
    "                raise ValueError(f'Three values should be provided for train/val/test split sizes. Instead received {len(self.split_sizes)} value(s).')\n",
    "\n",
    "            if self.separate_val_path is None and self.separate_test_path is None:  # separate data paths are not provided\n",
    "                if len(self.split_sizes) != 3:\n",
    "                    raise ValueError(f'Three values should be provided for train/val/test split sizes. Instead received {len(self.split_sizes)} value(s).')\n",
    "                if self.split_sizes[0] == 0.:\n",
    "                    raise ValueError(f'Provided split size for train split must be nonzero. Received split size {self.split_sizes[0]}')\n",
    "                if self.split_sizes[1] == 0.:\n",
    "                    raise ValueError(f'Provided split size for validation split must be nonzero. Received split size {self.split_sizes[1]}')\n",
    "\n",
    "            elif self.separate_val_path is not None and self.separate_test_path is None: # separate val path only\n",
    "                if len(self.split_sizes) == 2: # allow input of just 2 values\n",
    "                    self.split_sizes = [self.split_sizes[0], 0., self.split_sizes[1]]\n",
    "                if self.split_sizes[0] == 0.:\n",
    "                    raise ValueError('Provided split size for train split must be nonzero.')\n",
    "                if self.split_sizes[1] != 0.:\n",
    "                    raise ValueError(f'Provided split size for validation split must be 0 because validation set is provided separately. Received split size {self.split_sizes[1]}')\n",
    "\n",
    "            elif self.separate_val_path is None and self.separate_test_path is not None: # separate test path only\n",
    "                if len(self.split_sizes) == 2: # allow input of just 2 values\n",
    "                    self.split_sizes = [self.split_sizes[0], self.split_sizes[1], 0.]\n",
    "                if self.split_sizes[0] == 0.:\n",
    "                    raise ValueError('Provided split size for train split must be nonzero.')\n",
    "                if self.split_sizes[1] == 0.:\n",
    "                    raise ValueError('Provided split size for validation split must be nonzero.')\n",
    "                if self.split_sizes[2] != 0.:\n",
    "                    raise ValueError(f'Provided split size for test split must be 0 because test set is provided separately. Received split size {self.split_sizes[2]}')\n",
    "\n",
    "\n",
    "            else: # both separate data paths are provided\n",
    "                if self.split_sizes != [1., 0., 0.]:\n",
    "                    raise ValueError(f'Separate data paths were provided for val and test splits. Split sizes should not also be provided. Received split sizes: {self.split_sizes}')\n",
    "\n",
    "        # Test settings\n",
    "        if self.test:\n",
    "            self.epochs = 0\n",
    "\n",
    "        # Validate features are provided for separate validation or test set for each of the kinds of additional features\n",
    "        for (features_argument, base_features_path, val_features_path, test_features_path) in [\n",
    "            ('`--features_path`', self.features_path, self.separate_val_features_path, self.separate_test_features_path),\n",
    "            ('`--phase_features_path`', self.phase_features_path, self.separate_val_phase_features_path, self.separate_test_phase_features_path),\n",
    "            ('`--atom_descriptors_path`', self.atom_descriptors_path, self.separate_val_atom_descriptors_path, self.separate_test_atom_descriptors_path),\n",
    "            ('`--bond_descriptors_path`', self.bond_descriptors_path, self.separate_val_bond_descriptors_path, self.separate_test_bond_descriptors_path),\n",
    "            ('`--constraints_path`', self.constraints_path, self.separate_val_constraints_path, self.separate_test_constraints_path)\n",
    "        ]:\n",
    "            if base_features_path is not None:\n",
    "                if self.separate_val_path is not None and val_features_path is None:\n",
    "                    raise ValueError(f'Additional features were provided using the argument {features_argument}. The same kinds of features must be provided for the separate validation set.')\n",
    "                if self.separate_test_path is not None and test_features_path is None:\n",
    "                    raise ValueError(f'Additional features were provided using the argument {features_argument}. The same kinds of features must be provided for the separate test set.')\n",
    "\n",
    "        # validate extra atom descriptor options\n",
    "        if self.overwrite_default_atom_features and self.atom_descriptors != 'feature':\n",
    "            raise NotImplementedError('Overwriting of the default atom descriptors can only be used if the'\n",
    "                                      'provided atom descriptors are features.')\n",
    "\n",
    "        if not self.atom_descriptor_scaling and self.atom_descriptors is None:\n",
    "            raise ValueError('Atom descriptor scaling is only possible if additional atom features are provided.')\n",
    "\n",
    "        # validate extra bond descriptor options\n",
    "        if self.overwrite_default_bond_features and self.bond_descriptors != 'feature':\n",
    "            raise NotImplementedError('Overwriting of the default bond descriptors can only be used if the'\n",
    "                                      'provided bond descriptors are features.')\n",
    "\n",
    "        if not self.bond_descriptor_scaling and self.bond_descriptors is None:\n",
    "            raise ValueError('Bond descriptor scaling is only possible if additional bond features are provided.')\n",
    "\n",
    "        if self.bond_descriptors == 'descriptor' and not self.is_atom_bond_targets:\n",
    "            raise NotImplementedError('Bond descriptors as descriptor can only be used with `--is_atom_bond_targets`.')\n",
    "\n",
    "        # normalize target weights\n",
    "        if self.target_weights is not None:\n",
    "            avg_weight = sum(self.target_weights)/len(self.target_weights)\n",
    "            self.target_weights = [w/avg_weight for w in self.target_weights]\n",
    "            if min(self.target_weights) < 0:\n",
    "                raise ValueError('Provided target weights must be non-negative.')\n",
    "\n",
    "        # check if key molecule index is outside of the number of molecules\n",
    "        if self.split_key_molecule >= self.number_of_molecules:\n",
    "            raise ValueError('The index provided with the argument `--split_key_molecule` must be less than the number of molecules. Note that this index begins with 0 for the first molecule. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1daaf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
